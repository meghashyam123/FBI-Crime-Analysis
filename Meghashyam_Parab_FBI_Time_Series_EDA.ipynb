{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - FBI Crime Time Series Forecasting\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1** - Meghashyam Parab\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä FBI Crime Time Series Forecasting üîç\n",
        "\n",
        "Predicting Tomorrow‚Äôs Crime Trends, Today\n",
        "\n",
        "Crime patterns are not random; they follow trends, seasonality, and hidden correlations that can be uncovered with the power of time series forecasting. This project leverages machine learning and deep learning techniques to analyze historical FBI crime data and predict future crime occurrences across different categories.\n",
        "\n",
        "-----\n",
        "\n",
        "üöÄ Key Features\n",
        "\n",
        "üîπ Data-Driven Insights ‚Äì Analyzing years of FBI crime records to detect patterns and trends.\n",
        "\n",
        "üîπ Time Series Modeling ‚Äì Using ARIMA, LSTMs, Prophet, and other forecasting techniques.\n",
        "\n",
        "üîπ Interactive Visualizations ‚Äì Bringing crime trends to life with dynamic charts.\n",
        "\n",
        "üîπ Geospatial Analysis ‚Äì Mapping crime hotspots for better policy-making.\n",
        "\n",
        "üîπ Real-World Applications ‚Äì Helping law enforcement and policymakers make data-informed decisions.\n",
        "\n",
        "-----\n",
        "\n",
        "üõ†Ô∏è Tech Stack\n",
        "\n",
        "\n",
        "üìå Python, Pandas, NumPy ‚Äì Data preprocessing & analysis\n",
        "\n",
        "üìå TensorFlow, PyTorch ‚Äì Deep learning models\n",
        "\n",
        "üìå Facebook Prophet, ARIMA ‚Äì Time series forecasting\n",
        "\n",
        "üìå Matplotlib, Seaborn, Plotly ‚Äì Data visualization\n",
        "\n",
        "üìå Power BI ‚Äì Interactive dashboard"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/meghashyam123/FBI-Crime-Analysis"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context:\n",
        "\n",
        "The FBI Crime Data is often used to assess trends, patterns, and geographic influences on crime rates across various regions. Law enforcement agencies, urban planners, and policymakers rely on this data to allocate resources, optimize safety programs, and devise crime prevention strategies.\n",
        "\n",
        "Problem:\n",
        "\n",
        "The goal is to analyze the relationship between geographic factors (latitude, longitude) and crime rates to identify high-risk areas, uncover patterns, and derive insights that can aid in improving public safety measures.\n",
        "\n",
        "Problem Statement:\n",
        "\n",
        "Given the FBI crime data, which includes information on crime incidents across different geographic locations, we aim to analyze how geographic factors such as latitude and longitude influence crime rates. Specifically, we seek to understand:\n",
        "\n",
        "*   Which regions experience higher crime rates based on geographic location.\n",
        "\n",
        "*   Whether there is any correlation between latitude and crime count or longitude and crime count.\n",
        "\n",
        "*   The potential geographic hotspots for crime and how law enforcement and urban planners can use this data to optimize resource allocation and improve crime prevention strategies.\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Define Your Business Objective?**"
      ],
      "metadata": {
        "id": "PH-0ReGfmX4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To identify patterns and geographic factors influencing crime rates in order to support data-driven decision-making for public safety initiatives, resource allocation, urban planning, and crime prevention.\n",
        "\n",
        "Specific Goals:\n",
        "\n",
        "Geographic Crime Mapping:\n",
        "\n",
        "*   Analyze the relationship between geographic coordinates (latitude and longitude) and crime counts.\n",
        "\n",
        "\n",
        "Crime Prevention Strategy:\n",
        "\n",
        "Use spatial data to help law enforcement and city planners develop targeted\n",
        "\n",
        "*   Use spatial data to help law enforcement and city planners develop targeted crime prevention strategies for specific regions.\n",
        "\n",
        "\n",
        "Urban Development Planning:\n",
        "\n",
        "*   Provide insights for urban planners to consider crime patterns in city zoning and infrastructure development decisions.\n",
        "\n",
        "\n",
        "Predictive Analysis:\n",
        "\n",
        "*   Forecast crime rates in different regions based on geographic factors, helping to implement proactive measures.\n",
        "\n"
      ],
      "metadata": {
        "id": "PhDvGCAqmjP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 20 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "file_path = \"Train.xlsx\"\n",
        "df = pd.read_excel('/content/Train.xlsx')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "L12hkM_TqsuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "2eOS0u0mq5Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "# Count duplicate rows\n",
        "num_duplicates = df.duplicated().sum()\n",
        "\n",
        "# Print the result\n",
        "print(f\"Number of duplicate rows: {num_duplicates}\")"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Display the missing values count for each column\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "\n",
        "import missingno as msno\n",
        "msno.matrix(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create the heatmap\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Rows')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UhKvpq3rrZj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "# Get the columns of the DataFrame\n",
        "columns = df.columns\n",
        "\n",
        "# Print the columns\n",
        "print(columns)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    print(f\"Unique values for '{column}': {unique_values}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "# Check if the 'ID' column exists before dropping\n",
        "if 'ID' in df.columns:\n",
        "    df.drop(['ID'], axis=1, inplace=True)\n",
        "else:\n",
        "    print(\"Column 'ID' not found in the DataFrame.\")\n",
        "\n",
        "\n",
        "\n",
        "# Handling Missing Values in 'Store_Type'\n",
        "# Assuming 'Store_Type' is categorical, we'll use mode imputation\n",
        "if 'ID' in df.columns:\n",
        "    df.drop(['ID'], axis=1, inplace=True)\n",
        "else:\n",
        "    print(\"Column 'ID' not found in the DataFrame.\")\n",
        "\n",
        "\n",
        "# Check if the column 'Location_Type' exists in the dataframe\n",
        "if 'Location_Type' in df.columns:\n",
        "    # Handling Missing Values in 'Location_Type'\n",
        "    # Assuming 'Location_Type' is categorical, we'll use mode imputation\n",
        "    location_type_mode = df['Location_Type'].mode()[0]\n",
        "    df['Location_Type'].fillna(location_type_mode, inplace=True)\n",
        "else:\n",
        "    print(\"Column 'Location_Type' not found in the DataFrame.\")\n",
        "\n",
        "\n",
        "# Check if the column 'Region_Code' exists in the dataframe\n",
        "if 'Region_Code' in df.columns:\n",
        "    # Handling Missing Values in 'Region_Code'\n",
        "    # Assuming 'Region_Code' is categorical, we'll use mode imputation\n",
        "    region_code_mode = df['Region_Code'].mode()[0]\n",
        "    df['Region_Code'].fillna(region_code_mode, inplace=True)\n",
        "else:\n",
        "    print(\"Column 'Region_Code' not found in the DataFrame.\")\n",
        "\n",
        "# Check if the column 'Holiday' exists in the dataframe\n",
        "if 'Holiday' in df.columns:\n",
        "    # Handling Missing Values in 'Holiday'\n",
        "    # Assuming 'Holiday' is numerical, we'll use median imputation\n",
        "    holiday_median = df['Holiday'].median()\n",
        "    df['Holiday'].fillna(holiday_median, inplace=True)\n",
        "else:\n",
        "    print(\"Column 'Holiday' not found in the DataFrame.\")\n",
        "\n",
        "# Check if the column '#Order' exists in the dataframe\n",
        "if '#Order' in df.columns:\n",
        "    # Handling Missing Values in '#Order'\n",
        "    # Assuming '#Order' is numerical, we'll use median imputation\n",
        "    order_median = df['#Order'].median()\n",
        "    df['#Order'].fillna(order_median, inplace=True)\n",
        "else:\n",
        "    print(\"Column '#Order' not found in the DataFrame.\")\n",
        "\n",
        "\n",
        "# Check if the column 'Sales' exists in the dataframe\n",
        "if 'Sales' in df.columns:\n",
        "    # Handling Missing Values in 'Sales'\n",
        "    # Assuming 'Sales' is numerical, we'll use median imputation\n",
        "    sales_median = df['Sales'].median()\n",
        "    df['Sales'].fillna(sales_median, inplace=True)\n",
        "else:\n",
        "    print(\"Column 'Sales' not found in the DataFrame.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "BfVkSCX7xm52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1: Crime Type Distribution (Bar Chart)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Count occurrences of each crime type\n",
        "crime_counts = df['TYPE'].value_counts()\n",
        "\n",
        "# Create a bar plot\n",
        "sns.barplot(x=crime_counts.index, y=crime_counts.values, palette=\"viridis\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Crime Type\", fontsize=12)\n",
        "plt.ylabel(\"Number of Crimes\", fontsize=12)\n",
        "plt.title(\"Crime Type Distribution\", fontsize=14)\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Chart - 2: Top 10 Crime Locations (Bar Chart)\n",
        "\n",
        "# Count occurrences of crimes by location\n",
        "top_locations = df['HUNDRED_BLOCK'].value_counts().head(10)\n",
        "\n",
        "# Set figure size\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create a bar plot\n",
        "sns.barplot(x=top_locations.values, y=top_locations.index, palette=\"magma\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Number of Crimes\", fontsize=12)\n",
        "plt.ylabel(\"Location (Hundred Block)\", fontsize=12)\n",
        "plt.title(\"Top 10 Crime Locations\", fontsize=14)\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming your dataframe is called 'df'\n",
        "\n",
        "# 1. Group data by year and crime type, then count occurrences\n",
        "crime_trends = df.groupby(['YEAR', 'TYPE'])['TYPE'].count().reset_index(name='Count')\n",
        "\n",
        "# 2. Create a line plot using Seaborn\n",
        "plt.figure(figsize=(12, 6))  # Adjust figure size as needed\n",
        "sns.lineplot(data=crime_trends, x='YEAR', y='Count', hue='TYPE')\n",
        "plt.title('Crime Trends Over Time', fontsize=14)\n",
        "plt.xlabel('Year', fontsize=12)\n",
        "plt.ylabel('Number of Crimes', fontsize=12)\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.legend(title='Crime Type')  # Add a legend\n",
        "plt.tight_layout()  # Adjust layout for better spacing\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a creative plot for Crime by Weekday\n",
        "\n",
        "# Assuming your dataframe is called 'df' and has a 'Date' column\n",
        "\n",
        "# 1. Extract Day of the Week from 'Date' column\n",
        "df['DayOfWeek'] = pd.to_datetime(df['Date']).dt.day_name() # Extract day of the week and create a new 'DayOfWeek' column\n",
        "\n",
        "# 2. Group data by day of the week and crime type, then count occurrences\n",
        "crime_by_weekday = df.groupby(['DayOfWeek', 'TYPE'])['TYPE'].count().reset_index(name='Count')\n",
        "\n",
        "# 3. Create a bar plot using Seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=crime_by_weekday, x='DayOfWeek', y='Count', hue='TYPE')\n",
        "plt.title('Crime Count by Day of the Week', fontsize=14)\n",
        "plt.xlabel('Day of the Week', fontsize=12)\n",
        "plt.ylabel('Number of Crimes', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Crime Type')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# --- Creative Plot Ideas based on Crime by Weekday ---\n",
        "\n",
        "# Example Code Snippet (Idea 1 - Heatmap):\n",
        "\n",
        "# Assuming 'crime_by_weekday' is already created\n",
        "crime_pivot = crime_by_weekday.pivot(index=\"TYPE\", columns=\"DayOfWeek\", values=\"Count\")\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(crime_pivot, annot=True, fmt=\"d\", cmap=\"YlGnBu\")  #Use a different colormap if needed\n",
        "plt.title('Crime Types by Day of Week (Heatmap)')\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.ylabel('Crime Type')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0xFa6Uvhj5GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have a DataFrame called 'df' with columns 'Hour' and 'Crime_Count'\n",
        "# Replace 'Crime_Count' with the actual column representing crime frequency\n",
        "\n",
        "# Sample data (replace with your actual data)\n",
        "hours = range(24)\n",
        "crime_counts = [2, 1, 0, 1, 2, 5, 8, 12, 15, 10, 8, 7, 6, 7, 9, 11, 13, 10, 8, 5, 3, 2, 1, 1]\n",
        "\n",
        "# Set up the plot\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax = fig.add_subplot(111, projection='polar')\n",
        "\n",
        "# Define angles for each hour (24 hours in a circle)\n",
        "theta = np.linspace(0, 2 * np.pi, len(hours), endpoint=False)\n",
        "\n",
        "# Create the bars\n",
        "bars = ax.bar(theta, crime_counts, width=0.5, bottom=0.0, color='skyblue', alpha=0.7)\n",
        "\n",
        "# Customize the plot\n",
        "ax.set_theta_zero_location(\"N\")  # Set 0 degrees at the top\n",
        "ax.set_theta_direction(-1)  # Clockwise direction\n",
        "ax.set_xticks(theta)  # Set ticks for each hour\n",
        "ax.set_xticklabels([str(h) for h in hours])  # Hour labels\n",
        "ax.set_yticklabels([])  # Hide radial ticks\n",
        "ax.set_title(\"Crime by Hour of the Day (Radial Bar Chart)\", fontsize=14)\n",
        "\n",
        "# Add a grid\n",
        "ax.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "dj8ISaatx34a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a plot fot Crime Heatmap by Location\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is your DataFrame and it has columns 'Latitude', 'Longitude', and 'Crime_Count'\n",
        "# Replace 'Crime_Count' with the actual column name representing the frequency of crime\n",
        "\n",
        "# Sample data (replace with your actual data)\n",
        "# Create sample data (replace this with your actual data)\n",
        "data = {'Latitude': [47.6062, 47.6062, 47.6097, 47.6145, 47.5990],\n",
        "        'Longitude': [-122.3321, -122.3390, -122.3354, -122.3321, -122.3295],\n",
        "        'Crime_Count': [5, 2, 8, 1, 10]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(10, 8))  # Adjust figure size as needed\n",
        "sns.kdeplot(x=df['Longitude'], y=df['Latitude'], cmap=\"Reds\", shade=True, shade_lowest=False)\n",
        "plt.scatter(df['Longitude'], df['Latitude'], c=df['Crime_Count'], cmap=\"Reds\", s=df['Crime_Count'] * 10) # Size of points based on crime count\n",
        "plt.colorbar(label='Crime Count')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('Crime Heatmap by Location')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ##### 1. Why did you pick the specific chart?\n",
        "# A heatmap effectively visualizes the density of crimes across different locations. The color intensity represents the concentration of crime in specific areas, offering a quick overview of crime hotspots.\n",
        "\n",
        "# ##### 2. What is/are the insight(s) found from the chart?\n",
        "# Insights will depend on the actual data.  Generally, you'd look for clusters of high crime density, helping identify areas that might need more police presence.\n",
        "\n",
        "\n",
        "# ##### 3. Will the gained insights help creating a positive business impact?\n",
        "# Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "# Yes. Law enforcement agencies can use this information to strategically allocate resources to high-crime areas. This proactive approach can lead to a reduction in crime rates and improved public safety in these locations.  Conversely, areas with consistently low crime density may see resources reduced without a negative impact on public safety.\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install squarify #installing squarify package using pip\n",
        "# prompt: create a creative plot for Crime Distribution by Neighborhood\n",
        "\n",
        "# Assuming 'df' is your DataFrame and it has columns 'Neighborhood', 'Crime_Type', and potentially 'Crime_Count'\n",
        "\n",
        "# Sample Data (Replace with your actual data)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data = {'Neighborhood': ['A', 'A', 'B', 'B', 'B', 'C', 'C', 'A', 'B', 'C'],\n",
        "        'Crime_Type': ['Theft', 'Vandalism', 'Theft', 'Assault', 'Vandalism', 'Theft', 'Assault', 'Vandalism', 'Theft', 'Theft'],\n",
        "        'Crime_Count': [3, 1, 5, 2, 3, 2, 1, 1, 4, 2]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Group data by neighborhood and crime type\n",
        "neighborhood_crime = df.groupby(['Neighborhood', 'Crime_Type'])['Crime_Count'].sum().reset_index()\n",
        "\n",
        "# Create a treemap\n",
        "import squarify\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "squarify.plot(sizes=neighborhood_crime['Crime_Count'], label=[f'{n} - {c} ({count})' for n, c, count in zip(neighborhood_crime['Neighborhood'], neighborhood_crime['Crime_Type'], neighborhood_crime['Crime_Count'])], alpha=.8 )\n",
        "plt.title('Crime Distribution by Neighborhood and Type (Treemap)')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Alternative Visualization:  Stacked Bar Chart\n",
        "\n",
        "neighborhood_crime_pivot = neighborhood_crime.pivot(index='Neighborhood', columns='Crime_Type', values='Crime_Count').fillna(0)\n",
        "neighborhood_crime_pivot.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "plt.title('Crime Distribution by Neighborhood and Type (Stacked Bar Chart)')\n",
        "plt.xlabel('Neighborhood')\n",
        "plt.ylabel('Number of Crimes')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Crime Type')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a Crime Hotspots Map plot\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'df' is your DataFrame and it has columns 'Latitude', 'Longitude', and 'Crime_Count'\n",
        "# Replace 'Crime_Count' with the actual column name representing the frequency of crime\n",
        "\n",
        "# Sample data (replace with your actual data)\n",
        "# Create sample data (replace this with your actual data)\n",
        "data = {'Latitude': [47.6062, 47.6062, 47.6097, 47.6145, 47.5990, 47.6030, 47.6110],\n",
        "        'Longitude': [-122.3321, -122.3390, -122.3354, -122.3321, -122.3295, -122.3350, -122.3270],\n",
        "        'Crime_Count': [5, 2, 8, 1, 10, 3, 7]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Create the scatter plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(df['Longitude'], df['Latitude'], s=df['Crime_Count'] * 20, c=df['Crime_Count'], cmap='viridis', alpha=0.7)\n",
        "plt.colorbar(label='Crime Count')\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('Crime Hotspots Map')\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming your DataFrame is called 'df'\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(12, 10))  # Adjust figure size as needed\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Heatmap', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "source": [
        "# Pair Plot visualization\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming your DataFrame is called 'df'\n",
        "\n",
        "# Create the pair plot\n",
        "# Replace 'target_variable' with an actual column name from your DataFrame or remove hue argument if not needed.\n",
        "# Example: If 'Crime_Type' is a column in your DataFrame and you want to color points by crime type:\n",
        "# Check if the column 'Crime_Type' exists in your DataFrame\n",
        "if 'Crime_Type' in df.columns:\n",
        "    sns.pairplot(df, hue='Crime_Type')\n",
        "else:\n",
        "    print(\"Column 'Crime_Type' not found. Creating pairplot without hue.\")\n",
        "    sns.pairplot(df)  # Create pairplot without hue\n",
        "\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "4LafLRgJ4I8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Solution to Business Objective**"
      ],
      "metadata": {
        "id": "JcMwzZxoAimU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What do you suggest the client to achieve Business Objective ?\n",
        "Explain Briefly."
      ],
      "metadata": {
        "id": "8G2x9gOozGDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ Business Objective: Enhancing Crime Prevention & Resource Allocation\n",
        "üîç Goal: Use predictive analytics to forecast crime trends, helping law enforcement, policymakers, and urban planners make data-driven decisions.\n",
        "\n",
        "‚úÖ Recommended Actions for the Client\n",
        "\n",
        "1Ô∏è‚É£ Build a Crime Prediction Dashboard üìä\n",
        "\n",
        "üîπ What? Develop an interactive web dashboard to visualize historical and forecasted crime trends.\n",
        "\n",
        "üîπ Why? Enables real-time monitoring and helps law enforcement allocate resources proactively.\n",
        "\n",
        "üîπ How? Use Streamlit / Flask with Python to display forecasts, crime heatmaps, and insights.\n",
        "\n",
        "----\n",
        "\n",
        "2Ô∏è‚É£ Identify Crime Hotspots & Trends üåç\n",
        "\n",
        "üîπ What? Perform geospatial analysis to detect high-crime areas.\n",
        "\n",
        "üîπ Why? Helps authorities focus on specific neighborhoods for crime prevention efforts.\n",
        "\n",
        "üîπ How? Use GeoPandas, Folium, and Plotly to create interactive crime maps.\n",
        "\n",
        "------\n",
        "\n",
        "3Ô∏è‚É£ Implement Real-Time Crime Alerts üö®\n",
        "\n",
        "üîπ What? Develop an early warning system based on forecasted crime spikes.\n",
        "\n",
        "üîπ Why? Law enforcement can deploy officers to high-risk areas before crimes occur.\n",
        "\n",
        "üîπ How? Use machine learning models (LSTM, Prophet, ARIMA) to generate alerts based on trends.\n",
        "\n",
        "\n",
        "------\n",
        "\n",
        "\n",
        "4Ô∏è‚É£ Understand Crime Patterns by Time & Seasonality üïí\n",
        "\n",
        "üîπ What? Analyze seasonal crime trends (e.g., higher theft rates in holiday seasons).\n",
        "\n",
        "üîπ Why? Helps in event-based security planning and resource allocation.\n",
        "\n",
        "üîπ How? Use time-series decomposition and anomaly detection techniques.\n",
        "\n",
        "\n",
        "-----\n",
        "\n",
        "5Ô∏è‚É£ Policy & Urban Planning Recommendations üèôÔ∏è\n",
        "\n",
        "üîπ What? Provide crime prevention recommendations to city officials & law enforcement.\n",
        "\n",
        "üîπ Why? Helps make informed decisions on street lighting, CCTV placements, and patrol scheduling.\n",
        "\n",
        "üîπ How? Use AI-driven predictive analytics to suggest improvements based on crime trends.\n",
        "\n"
      ],
      "metadata": {
        "id": "pASKb0qOza21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By analyzing the FBI crime data, we can uncover geographic trends that reveal regions with higher crime rates based on latitude and longitude. The findings suggest that latitude and longitude have a measurable impact on crime distribution, with certain areas showing higher crime densities. This insight enables more effective resource allocation for law enforcement, supports proactive crime prevention efforts, and informs urban planning decisions to improve community safety. This analysis provides valuable data for strategic crime control and policy development."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your EDA Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}